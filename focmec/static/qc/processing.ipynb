{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "def update_excel_file(tanggal, hari, jam, kelompok, operator, NIP):\n",
    "    # Load the workbook and select the active worksheet\n",
    "    workbook = openpyxl.load_workbook('QC Seiscomp.xlsx')\n",
    "    sheet = workbook.active\n",
    "\n",
    "    # Fill cell G2 with the specified value\n",
    "    sheet['G2'] = ': ' + tanggal\n",
    "    sheet['G3'] = ': ' + hari\n",
    "    sheet['G4'] = f': {jam} - selesai'\n",
    "    sheet['G5'] = f': {kelompok}'\n",
    "    sheet['M18'] = tanggal\n",
    "    sheet['M24'] = operator\n",
    "    NIP = sheet['M25'] = 'NIP. ' + NIP\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save('QC Seiscomp.xlsx')\n",
    "\n",
    "# Example usage\n",
    "update_excel_file('20 Desember 2020', 'Senin', '14:00', 'Kel. 1', 'Fajar', '199411052014111001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n",
      "1 [1, 2, 3, 4, 'prev', 1]\n",
      "2 [5, 6, 7, 8, 'prev', 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "# Sample CSV string\n",
    "csv_string = \"apple,banana,cherry,orange\\n1,2,3,4\\n5,6,7,8\"\n",
    "\n",
    "# Create a DataFrame from the CSV string\n",
    "df = pd.read_csv(StringIO(csv_string))\n",
    "rows = dataframe_to_rows(df, index=False, header=False)\n",
    "\n",
    "# print df rows size\n",
    "print(len(df))\n",
    "df['prev'] = 'prev'\n",
    "df['no'] = range(1, len(df)+1)\n",
    "print(df.shape[1])\n",
    "\n",
    "for r_idx, row in enumerate(rows, 1):\n",
    "    print(r_idx, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\QC\\ebast\\qc\\static\\qc\\QC.xlsx\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def convert_xlsx_to_pdf(filename):\n",
    "  \"\"\"\n",
    "  Converts an XLSX file to PDF using the LibreOffice command-line interface.\n",
    "\n",
    "  Args:\n",
    "    filename: Path to the input XLSX file.\n",
    "\n",
    "  Returns:\n",
    "    True if the conversion was successful, False otherwise.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    command = [\"soffice\", \"--headless\", \"--convert-to\", \"pdf:\\\"impress_pdf_Export\\\"\", filename]\n",
    "    subprocess.run(command, check=True) \n",
    "    return True\n",
    "  except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error converting {filename} to PDF: {e}\")\n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "filename = os.path.join(os.getcwd(), 'QC.xlsx')\n",
    "print(filename)\n",
    "# convert_xlsx_to_pdf(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         EventID       Datetime (UTC)  Creation Time (UTC)       Mode  \\\n",
      "0    gfz2025ehnv  2025-03-03 01:04:52  2025-03-03 02:28:48     manual   \n",
      "1    gfz2025ehmf  2025-03-03 00:15:30  2025-03-03 00:20:49  automatic   \n",
      "2    gfz2025ehep  2025-03-02 20:24:30  2025-03-02 20:33:28  automatic   \n",
      "3    gfz2025ehdv  2025-03-02 20:01:32  2025-03-02 20:09:38  automatic   \n",
      "4    gfz2025ehci  2025-03-02 19:16:48  2025-03-02 19:22:08  automatic   \n",
      "..           ...                  ...                  ...        ...   \n",
      "175  bmg2025acjo  2025-01-02 07:06:40  2025-01-02 09:08:21  automatic   \n",
      "176  bmg2025acgm  2025-01-02 05:32:21  2025-01-02 05:44:24     manual   \n",
      "177  bmg2025abbi  2025-01-01 13:48:18  2025-01-01 14:34:28  automatic   \n",
      "178                              None                 None       None   \n",
      "179                              None                 None       None   \n",
      "\n",
      "        Status   Mag Type M       Lat      Long     D  ...  Tplg  Tazi   Nval  \\\n",
      "0    confirmed   4.0     Mw    0.9312  100.0418   196  ...    69    31   0.22   \n",
      "1      NOT SET   4.9     Mw   -3.9954  103.3654   613  ...     8   350   0.28   \n",
      "2      NOT SET   4.6     Mw   -3.3472  129.4760   154  ...    50   206   0.30   \n",
      "3      NOT SET   3.6     Mw   -0.7104   97.4029    10  ...    17   105   0.11   \n",
      "4      NOT SET   4.8     Mw   -0.9279  120.2715   595  ...    29   187  -0.64   \n",
      "..         ...   ...    ...       ...       ...   ...  ...   ...   ...    ...   \n",
      "175    NOT SET   5.5     Mw   -3.8166  151.5800    26  ...    32   326  -0.32   \n",
      "176  confirmed   4.9     Mw   -0.2373  125.2279    54  ...    52   263   0.37   \n",
      "177    NOT SET   6.2     Mw  -56.4793  -26.8590    93  ...    21   179   0.09   \n",
      "178       None  None   None      None      None  None  ...  None  None   None   \n",
      "179       None  None   None      None      None  None  ...  None  None   None   \n",
      "\n",
      "     Nplg  Nazi   Pval  Pplg  Pazi Fit(%) CLVD (%)  \n",
      "0      20   195  -1.29     5   287  78.62    34.68  \n",
      "1      80   137  -3.29     5   259  67.59    16.98  \n",
      "2      40    31  -1.21     2   299  81.40    50.37  \n",
      "3      23     7  -3.33    61   228  74.64     6.88  \n",
      "4      59   348  -1.51     9    93  58.96    59.57  \n",
      "..    ...   ...    ...   ...   ...    ...      ...  \n",
      "175    51   187  -2.03    21    69  66.37    27.42  \n",
      "176    31    46  -2.70    19   147  70.30    27.32  \n",
      "177    59   310  -2.23    21    81  93.35     8.31  \n",
      "178  None  None   None  None  None   None     None  \n",
      "179  None  None   None  None  None   None     None  \n",
      "\n",
      "[180 rows x 34 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'No': 1,\n",
       "  'Date': datetime.date(2025, 3, 12),\n",
       "  'OT (UTC)': datetime.time(5, 42, 6),\n",
       "  'Lat': '6.6609',\n",
       "  'Long': '92.0575',\n",
       "  'Mag': '5.9',\n",
       "  'TypeMag': 'Mw',\n",
       "  'D(Km)': '10',\n",
       "  'S1': '175',\n",
       "  'D1': '59',\n",
       "  'R1': '112',\n",
       "  'S2': '317',\n",
       "  'D2': '37',\n",
       "  'R2': '58',\n",
       "  'Fit(%)': '84.90',\n",
       "  'CLVD (%)': '30.57'},\n",
       " {'No': 2,\n",
       "  'Date': datetime.date(2025, 3, 12),\n",
       "  'OT (UTC)': datetime.time(12, 51, 31),\n",
       "  'Lat': '-7.5164',\n",
       "  'Long': '129.2063',\n",
       "  'Mag': '5.0',\n",
       "  'TypeMag': 'Mw',\n",
       "  'D(Km)': '124',\n",
       "  'S1': '85',\n",
       "  'D1': '51',\n",
       "  'R1': '67',\n",
       "  'S2': '300',\n",
       "  'D2': '45',\n",
       "  'R2': '116',\n",
       "  'Fit(%)': '88.16',\n",
       "  'CLVD (%)': '38.25'},\n",
       " {'No': 3,\n",
       "  'Date': datetime.date(2025, 3, 12),\n",
       "  'OT (UTC)': datetime.time(15, 9, 50),\n",
       "  'Lat': '8.2152',\n",
       "  'Long': '127.5588',\n",
       "  'Mag': '5.6',\n",
       "  'TypeMag': 'Mw',\n",
       "  'D(Km)': '54',\n",
       "  'S1': '106',\n",
       "  'D1': '40',\n",
       "  'R1': '-156',\n",
       "  'S2': '358',\n",
       "  'D2': '75',\n",
       "  'R2': '-52',\n",
       "  'Fit(%)': '81.91',\n",
       "  'CLVD (%)': '46.69'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def clean_fm_data(data, start_datetime='2025-03-12 00:00:00', end_datetime='2025-03-13 00:00:00'):\n",
    "    text = data.decode('utf-8')\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    processed_lines = []\n",
    "    for i, line in enumerate(lines):\n",
    "        line = '|'.join(part.strip() for part in line.split('|'))\n",
    "        processed_lines.append(line)\n",
    "\n",
    "    df = pd.DataFrame([x.split('|') for x in processed_lines[1:]], columns=processed_lines[0].split('|'))\n",
    "    print(df)\n",
    "    df['Datetime (UTC)'] = pd.to_datetime(df['Datetime (UTC)'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    def select_data_by_datetime_range(df, start_datetime, end_datetime):\n",
    "        mask = (df['Datetime (UTC)'] >= start_datetime) & (df['Datetime (UTC)'] <= end_datetime)\n",
    "        return df.loc[mask]\n",
    "\n",
    "    df_selected = select_data_by_datetime_range(df, start_datetime, end_datetime)\n",
    "\n",
    "    # sort the df_selected by 'Datetime (UTC)'\n",
    "    df_selected = df_selected.sort_values(by='Datetime (UTC)')\n",
    "\n",
    "    # divide the 'Datetime (UTC)' column into 'Date' and 'OT (UTC)' columns, and put them in the first two columns, remove the 'Datetime (UTC)' column\n",
    "    df_selected['Date'] = df_selected['Datetime (UTC)'].dt.date\n",
    "    df_selected['OT (UTC)'] = df_selected['Datetime (UTC)'].dt.time\n",
    "    df_selected = df_selected[['Date', 'OT (UTC)'] + [col for col in df_selected.columns if col != 'Datetime (UTC)']]\n",
    "    df_selected = df_selected.reset_index(drop=True)\n",
    "\n",
    "    # sort the columns to be 'Date', 'OT (UTC)', 'Lat', 'Long', 'Mag', 'D(Km)', 'Phase', 'RMS', 'Az.Gap', 'Region', but first turn the respective column names into the desired ones\n",
    "    df_selected = df_selected.rename(columns={'D': 'D(Km)', 'Type M': 'TypeMag'})\n",
    "    df_selected = df_selected[['Date', 'OT (UTC)', 'Lat', 'Long', 'Mag', 'TypeMag', 'D(Km)', 'S1', 'D1', 'R1', 'S2', 'D2', 'R2', 'Fit(%)', 'CLVD (%)']]\n",
    "    df_selected = df_selected.reset_index(drop=True)\n",
    "\n",
    "    # Check for duplicate columns\n",
    "    df_selected = df_selected.loc[:, ~df_selected.columns.duplicated()]\n",
    "    \n",
    "    return df_selected\n",
    "\n",
    "def fetch_data(start_datetime='2025-03-12 00:00:00', end_datetime='2025-03-13 00:00:00'):\n",
    "    url = \"http://202.90.198.41/qc_focal.txt\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = clean_fm_data(response.content, start_datetime, end_datetime)\n",
    "        csv_data = data.to_csv(index=False)\n",
    "        table_data = data.insert(0, 'No', range(1, len(data) + 1))\n",
    "        table_data = data.to_dict(orient='records')\n",
    "        return table_data\n",
    "    #     return JsonResponse({'csv': csv_data, 'table_data': table_data})\n",
    "    # else:\n",
    "    #     return JsonResponse({'error': 'Failed to fetch data'}, status=500)\n",
    "    \n",
    "fetch_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
